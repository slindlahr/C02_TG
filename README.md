# ğŸ—ï¸ COâ‚‚ Analyse & Upload â€“ GCP Case Study

## ğŸ”§ Architekturentscheidung und BegrÃ¼ndung

### Verwendete Google Cloud Services

| Dienst              | Zweck                                 | Warum gewÃ¤hlt                                               |
|---------------------|----------------------------------------|-------------------------------------------------------------|
| **Cloud Run Service**        | Hoster fÃ¼r Python-API-Logik           | - VollstÃ¤ndig verwaltet<br>- Skaliert automatisch<br>- Einfach via HTTP triggerbar |
| **Cloud Scheduler**  | Automatisierung des Trigger-Vorgangs  | - Cron-Ã¤hnlich<br>- ZuverlÃ¤ssig<br>- Native Authentifizierung mit Cloud Run |
| **BigQuery**         | Datenziel / Cloud Data Warehouse      | - Hochperformantes SQL-Backend<br>- Kein Infrastruktur-Overhead<br>- Ideal fÃ¼r Analysezwecke |
| **Docker**           | Verpackung & Transport der App        | - Portabel<br>- Einheitlich Ã¼ber lokale und Cloud-Umgebung |

---

### âœ… Vorteile dieses Designs

- **Kosteneffizient**: Keine laufenden Ressourcen auÃŸerhalb der AusfÃ¼hrung.
- **Einfach skalierbar**: Cloud Run kÃ¼mmert sich um Skalierung.
- **Trennung von Logik und Trigger**: Bessere Wartbarkeit.
- **Manuell und automatisch ausfÃ¼hrbar**, ideal fÃ¼r hybride Nutzung.
- **Portabel** durch containerisierte App-Struktur (Docker).

---

### âš ï¸ Nachteile & Alternativen

| Alternative                    | Nachteile im Vergleich                                   |
|-------------------------------|----------------------------------------------------------|
| **Cloud Functions**           | EingeschrÃ¤nkteres Laufzeitverhalten, schwierigeres Debugging |
| **VM + Cronjob**              | Overhead fÃ¼r Wartung, geringere Skalierbarkeit           |
| **Composer (Airflow)**        | Overkill fÃ¼r einfachen tÃ¤glichen Task, aufwendiger Setup |
| **Pub/Sub Trigger**           | FÃ¼r einfache Zeitsteuerung unnÃ¶tig komplex               |

---

### ğŸ” VerbesserungsmÃ¶glichkeiten (Next Iteration)

- âœ… **Logging mit Google Cloud Logging** statt `print()`  
- âœ… **Secrets Manager verwenden** statt JSON-Datei im Image  
- âœ… **Monitoring mit Alerts**, z.â€¯B. bei Upload-FehlschlÃ¤gen  
- âœ… **Tests und Linting automatisieren**, z.â€¯B. mit GitHub Actions  
- âœ… **Parametrisierte ZeitrÃ¤ume Ã¼ber Cloud Run Argumente (Query-Params)**

---

## ğŸ“ Projektstruktur

```bash
C02_TG/
â”‚
â”œâ”€â”€ automation/               # Haupt-Pipeline
â”‚   â”œâ”€â”€ main.py               # Einstiegspunkt (von Cloud Run ausgefÃ¼hrt)
â”‚   â”œâ”€â”€ api_client.py         # API-Fetch & Datenbereinigung
â”‚   â”œâ”€â”€ analyse.py            # Tabellen-Erstellung aus Rohdaten
â”‚   â”œâ”€â”€ bigquery_upload.py    # Upload-Logik fÃ¼r BQ
â”‚   â””â”€â”€ requirements.txt      # Python-AbhÃ¤ngigkeiten
â”‚
â”œâ”€â”€ secrets/                  # (lokal vorhanden) BigQuery JSON Credential
â”‚
â”œâ”€â”€ Dockerfile                # Container-Bauplan
â””â”€â”€ README.md                 # Diese Datei
```

---

## âš™ï¸ AusfÃ¼hrung

### Manuelle AusfÃ¼hrung Ã¼ber Cloud Scheduler:
```
https://console.cloud.google.com/cloudscheduler?project=c02-tg&inv=1&invt=Ab5Hjg
```

### Automatische AusfÃ¼hrung:
TÃ¤glich Ã¼ber **Cloud Scheduler**, geplant um **08:00 Uhr (CET)**  
Zeitplan:  
```cron
0 8 * * *
```

---

## ğŸ“’ Hinweise zur lokalen Entwicklung

- Die App kann lokal Ã¼ber Docker ausgefÃ¼hrt werden:
```bash
docker build -t c02-analysis .
docker run -p 8080:8080 c02-analysis
```

- Es existiert ein separates **Jupyter Notebook**, mit dem dieselbe Logik lokal getestet und schrittweise ausgefÃ¼hrt werden kann. (z.â€¯B. fÃ¼r Debugging oder Exploration)

---

## ğŸ§  Ãœberblick Klassen & Funktionen

| Klasse/Funktion          | Zweck |
|--------------------------|-------|
| `ThurgauAPIClient`       | LÃ¤dt Daten von der offiziellen API |
| `DataCleaner`            | ErgÃ¤nzt UUID und Zeitstempel |
| `AnalyseC02Data`         | Erstellt strukturierte DataFrames fÃ¼r BigQuery |
| `BigQueryUploader`       | LÃ¤dt Tabellen in BigQuery hoch |
| `main.py` (Flask App)    | HTTP-Endpunkt, triggert gesamten Prozess |

---

## â±ï¸ ZeitrÃ¤ume anpassen

- Aktuell lÃ¤dt das Skript **alle verfÃ¼gbaren Daten bei jedem Lauf**.
- In zukÃ¼nftigen Iterationen kann der Zeitraum dynamisch gestaltet werden, z.â€¯B. Ã¼ber Query-Parameter an den Cloud Run Endpoint oder durch Vergleich mit bestehenden Daten in BigQuery.

---

**Autor:** Sebastian Lindlahr  
**Projekt:** COâ‚‚ Analyse Thurgau â€“ GCP Case Study  
