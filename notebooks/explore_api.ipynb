{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41fc51b9",
   "metadata": {},
   "source": [
    "# Aufgabe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c24b8",
   "metadata": {},
   "source": [
    "## 1 - API / Data-Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b2ef2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es wurden 720 Datensätze vom Dataset 'div-energie-8' geladen.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bfs_nr_gemeinde</th>\n",
       "      <th>erdoelbrennstoffe</th>\n",
       "      <th>gemeinde_name</th>\n",
       "      <th>jahr</th>\n",
       "      <th>energiebezugsflaeche</th>\n",
       "      <th>total</th>\n",
       "      <th>einwohner</th>\n",
       "      <th>erdgas</th>\n",
       "      <th>andere</th>\n",
       "      <th>uuid</th>\n",
       "      <th>loaded_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4881</td>\n",
       "      <td>1686.933</td>\n",
       "      <td>Amlikon-Bissegg</td>\n",
       "      <td>2015</td>\n",
       "      <td>113791</td>\n",
       "      <td>1686.933</td>\n",
       "      <td>1320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abc4371e-1ff9-4dd4-ba37-989209be13b2</td>\n",
       "      <td>2025-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4921</td>\n",
       "      <td>2217.241</td>\n",
       "      <td>Bussnang</td>\n",
       "      <td>2015</td>\n",
       "      <td>187360</td>\n",
       "      <td>3151.487</td>\n",
       "      <td>2262</td>\n",
       "      <td>932.375</td>\n",
       "      <td>1.871</td>\n",
       "      <td>1937b666-02c2-4345-8899-7739451601ff</td>\n",
       "      <td>2025-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4751</td>\n",
       "      <td>2836.259</td>\n",
       "      <td>Rickenbach (TG)</td>\n",
       "      <td>2015</td>\n",
       "      <td>227233</td>\n",
       "      <td>4585.831</td>\n",
       "      <td>2766</td>\n",
       "      <td>1745.491</td>\n",
       "      <td>4.081</td>\n",
       "      <td>69ff1b5f-5350-41c1-9dc8-0ef03bfee77e</td>\n",
       "      <td>2025-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4756</td>\n",
       "      <td>867.692</td>\n",
       "      <td>Schönholzerswilen</td>\n",
       "      <td>2015</td>\n",
       "      <td>72638</td>\n",
       "      <td>867.692</td>\n",
       "      <td>804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5ff1770b-d51d-4470-a423-ca37861ca445</td>\n",
       "      <td>2025-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4696</td>\n",
       "      <td>3593.640</td>\n",
       "      <td>Tägerwilen</td>\n",
       "      <td>2015</td>\n",
       "      <td>348780</td>\n",
       "      <td>6037.877</td>\n",
       "      <td>4377</td>\n",
       "      <td>2444.237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05823851-cbfa-4f0b-9c71-9148417aa6c9</td>\n",
       "      <td>2025-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>4806</td>\n",
       "      <td>1092.829</td>\n",
       "      <td>Eschenz</td>\n",
       "      <td>2023</td>\n",
       "      <td>168717</td>\n",
       "      <td>2234.899</td>\n",
       "      <td>1893</td>\n",
       "      <td>1142.070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d389d6bd-80b9-4fce-bbd8-5313c937aa52</td>\n",
       "      <td>2025-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>4724</td>\n",
       "      <td>2305.944</td>\n",
       "      <td>Eschlikon</td>\n",
       "      <td>2023</td>\n",
       "      <td>430312</td>\n",
       "      <td>5319.303</td>\n",
       "      <td>4864</td>\n",
       "      <td>3013.359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73c23e37-6f33-44f3-b559-ec17981b2508</td>\n",
       "      <td>2025-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>4741</td>\n",
       "      <td>1227.117</td>\n",
       "      <td>Lommis</td>\n",
       "      <td>2023</td>\n",
       "      <td>103746</td>\n",
       "      <td>1227.117</td>\n",
       "      <td>1267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f6860aa6-b5d0-4ea9-86d2-deffdc022f5c</td>\n",
       "      <td>2025-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>4441</td>\n",
       "      <td>1192.134</td>\n",
       "      <td>Salmsach</td>\n",
       "      <td>2023</td>\n",
       "      <td>116236</td>\n",
       "      <td>1862.043</td>\n",
       "      <td>1578</td>\n",
       "      <td>669.910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8bfae44d-8b09-44d2-a52c-0fc5b9295505</td>\n",
       "      <td>2025-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>4786</td>\n",
       "      <td>770.391</td>\n",
       "      <td>Wilen (TG)</td>\n",
       "      <td>2023</td>\n",
       "      <td>194909</td>\n",
       "      <td>2873.222</td>\n",
       "      <td>2501</td>\n",
       "      <td>2100.666</td>\n",
       "      <td>2.165</td>\n",
       "      <td>ef46e529-561e-42bb-a525-b27bf507ec0c</td>\n",
       "      <td>2025-08-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bfs_nr_gemeinde  erdoelbrennstoffe      gemeinde_name  jahr  \\\n",
       "0              4881           1686.933    Amlikon-Bissegg  2015   \n",
       "1              4921           2217.241           Bussnang  2015   \n",
       "2              4751           2836.259    Rickenbach (TG)  2015   \n",
       "3              4756            867.692  Schönholzerswilen  2015   \n",
       "4              4696           3593.640         Tägerwilen  2015   \n",
       "..              ...                ...                ...   ...   \n",
       "715            4806           1092.829            Eschenz  2023   \n",
       "716            4724           2305.944          Eschlikon  2023   \n",
       "717            4741           1227.117             Lommis  2023   \n",
       "718            4441           1192.134           Salmsach  2023   \n",
       "719            4786            770.391         Wilen (TG)  2023   \n",
       "\n",
       "     energiebezugsflaeche     total  einwohner    erdgas  andere  \\\n",
       "0                  113791  1686.933       1320       NaN     NaN   \n",
       "1                  187360  3151.487       2262   932.375   1.871   \n",
       "2                  227233  4585.831       2766  1745.491   4.081   \n",
       "3                   72638   867.692        804       NaN     NaN   \n",
       "4                  348780  6037.877       4377  2444.237     NaN   \n",
       "..                    ...       ...        ...       ...     ...   \n",
       "715                168717  2234.899       1893  1142.070     NaN   \n",
       "716                430312  5319.303       4864  3013.359     NaN   \n",
       "717                103746  1227.117       1267       NaN     NaN   \n",
       "718                116236  1862.043       1578   669.910     NaN   \n",
       "719                194909  2873.222       2501  2100.666   2.165   \n",
       "\n",
       "                                     uuid   loaded_at  \n",
       "0    abc4371e-1ff9-4dd4-ba37-989209be13b2  2025-08-02  \n",
       "1    1937b666-02c2-4345-8899-7739451601ff  2025-08-02  \n",
       "2    69ff1b5f-5350-41c1-9dc8-0ef03bfee77e  2025-08-02  \n",
       "3    5ff1770b-d51d-4470-a423-ca37861ca445  2025-08-02  \n",
       "4    05823851-cbfa-4f0b-9c71-9148417aa6c9  2025-08-02  \n",
       "..                                    ...         ...  \n",
       "715  d389d6bd-80b9-4fce-bbd8-5313c937aa52  2025-08-02  \n",
       "716  73c23e37-6f33-44f3-b559-ec17981b2508  2025-08-02  \n",
       "717  f6860aa6-b5d0-4ea9-86d2-deffdc022f5c  2025-08-02  \n",
       "718  8bfae44d-8b09-44d2-a52c-0fc5b9295505  2025-08-02  \n",
       "719  ef46e529-561e-42bb-a525-b27bf507ec0c  2025-08-02  \n",
       "\n",
       "[720 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "class ThurgauAPIClient:\n",
    "    \"\"\"Client to fetch and clean Open Government Data from Thurgau.\"\"\"\n",
    "\n",
    "    def __init__(self, base_url: str = \"https://data.tg.ch/api/records/1.0/search/\"):\n",
    "        self.base_url = base_url\n",
    "\n",
    "    def fetch_data(self, dataset: str, max_records: int = 1000) -> pd.DataFrame:\n",
    "        \"\"\"Fetches data from the Thurgau - Open Government Data API.\n",
    "\n",
    "        Args:\n",
    "            dataset (str): Unique dataset ID from the webpage's API description.\n",
    "            max_records (int, optional): Max rows to fetch. Defaults to 1000.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Table with requested data.\n",
    "        \"\"\"\n",
    "        \n",
    "        params = {\"dataset\": dataset, \"rows\": max_records}\n",
    "        response = requests.get(self.base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        records = [r[\"fields\"] for r in data.get(\"records\", [])]\n",
    "        df = pd.DataFrame(records)\n",
    "        print(f\"Es wurden {len(df)} Datensätze vom Dataset '{dataset}' geladen.\")\n",
    "        return df\n",
    "\n",
    "class DataCleaner:\n",
    "    \"\"\"Utility class for cleaning and enriching datasets with additional columns.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def add_uuid(df: pd.DataFrame, uuid_column: str = \"uuid\") -> pd.DataFrame:\n",
    "        \"\"\"Add a unique UUID to each row.\"\"\"\n",
    "        df[uuid_column] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def add_timestamp(df: pd.DataFrame, ts_column: str = \"loaded_at\") -> pd.DataFrame:\n",
    "        \"\"\"Add a timestamp to each row.\"\"\"\n",
    "        df[ts_column] = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        return df\n",
    "\n",
    "\n",
    "# Execution\n",
    "client = ThurgauAPIClient()\n",
    "df_c02 = client.fetch_data(dataset=\"div-energie-8\")\n",
    "\n",
    "cleaner = DataCleaner()\n",
    "df_c02 = cleaner.add_uuid(df_c02)\n",
    "df_c02 = cleaner.add_timestamp(df_c02)\n",
    "\n",
    "df_c02\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded81c71",
   "metadata": {},
   "source": [
    "## 2 - Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd1a51b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class AnalyseC02Data:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "        self.tables = {}  # Speicherung der dfs\n",
    "\n",
    "        # Data Cleaning\n",
    "        self.df['andere'] = self.df['andere'].fillna(0)\n",
    "        #Renaming\n",
    "        self.df = self.df.rename(columns={\"total\": \"c02_emissions\"})\n",
    "\n",
    "        # Analysen\n",
    "        self._prepare_kpis_pro_jahr()\n",
    "        self._prepare_lookerstudio_table()\n",
    "        self._prepare_energiemix()\n",
    "        self._prepare_gemeindeentwicklung()\n",
    "        self._prepare_entwicklung_einwohner_vs_C02()\n",
    "\n",
    "    def _prepare_kpis_pro_jahr(self):\n",
    "        df = self.df.groupby('jahr').agg({\n",
    "            'c02_emissions': 'sum',\n",
    "            'einwohner': 'sum'\n",
    "        }).reset_index()\n",
    "\n",
    "        df['energy_per_inhabitant'] = df['c02_emissions'] / df['einwohner']\n",
    "        df['growth_total_energy_pct'] = df['c02_emissions'].pct_change() * 100\n",
    "        df['growth_energy_per_inhabitant_pct'] = df['energy_per_inhabitant'].pct_change() * 100\n",
    "\n",
    "        # Cast datatypes\n",
    "        df[\"jahr\"] = pd.to_datetime(df[\"jahr\"].astype(str) + \"-01-01\")\n",
    "\n",
    "        self.tables['kpi_pro_jahr'] = df\n",
    "\n",
    "    def _prepare_lookerstudio_table(self):\n",
    "        df = self.df.copy()\n",
    "\n",
    "        # Optional: Datum im Format \"jahr\" als echtes Datum (z. B. 01.01.2023)\n",
    "        df[\"jahr\"] = pd.to_datetime(df[\"jahr\"].astype(str) + \"-01-01\")\n",
    "\n",
    "        # Kein groupby — keine Aggregation!\n",
    "        df = df[[\"jahr\", \"gemeinde_name\", \"einwohner\", \"c02_emissions\", \"energiebezugsflaeche\", \"loaded_at\"]].copy()\n",
    "\n",
    "        self.tables[\"lookerstudio_base\"] = df\n",
    "\n",
    "\n",
    "    def _prepare_energiemix(self):\n",
    "        df = self.df.copy()\n",
    "        # Summieren der Energiearten pro jahr\n",
    "        df_grouped = df.groupby(\"jahr\")[[\"erdoelbrennstoffe\", \"erdgas\", \"andere\"]].sum().reset_index()\n",
    "\n",
    "        # Umwandeln in Long-Format\n",
    "        df = df_grouped.melt(\n",
    "            id_vars=\"jahr\",\n",
    "            value_vars=[\"erdoelbrennstoffe\", \"erdgas\", \"andere\"],\n",
    "            var_name=\"energietraeger\",\n",
    "            value_name=\"menge\"\n",
    "        )\n",
    "\n",
    "        df[\"anteil_prozent\"] = df.groupby(\"jahr\")[\"menge\"].transform(lambda x: round(x / x.sum() * 100, 2))\n",
    "\n",
    "        # Cast datatypes\n",
    "        df[\"jahr\"] = pd.to_datetime(df[\"jahr\"].astype(str) + \"-01-01\")\n",
    "\n",
    "        self.tables['energiemix_pro_jahr'] = df\n",
    "\n",
    "\n",
    "    def _prepare_gemeindeentwicklung(self):\n",
    "        df = self.df.copy()\n",
    "        df['energy_per_inhabitant'] = df['c02_emissions'] / df['einwohner']\n",
    "\n",
    "        df = df[['bfs_nr_gemeinde', 'gemeinde_name', 'jahr', 'c02_emissions', 'energy_per_inhabitant']]\n",
    "\n",
    "        # Cast datatypes\n",
    "        df[\"jahr\"] = pd.to_datetime(df[\"jahr\"].astype(str) + \"-01-01\")\n",
    "\n",
    "        self.tables['gemeindeentwicklung'] = df\n",
    "\n",
    "\n",
    "    def _prepare_entwicklung_einwohner_vs_C02(self):\n",
    "        df = self.df.copy()\n",
    "        df = df[[\"jahr\", \"gemeinde_name\", \"einwohner\", \"c02_emissions\", \"energiebezugsflaeche\"]].copy()\n",
    "\n",
    "        df[\"C02_pro_qm\"] = df[\"c02_emissions\"] / df[\"energiebezugsflaeche\"] * 1000\n",
    "        df[\"C02_pro_einwohner\"] = df[\"c02_emissions\"] / df[\"einwohner\"] * 1000\n",
    "\n",
    "        # Cast datatypes\n",
    "        df[\"jahr\"] = pd.to_datetime(df[\"jahr\"].astype(str) + \"-01-01\")\n",
    "\n",
    "        self.tables[\"einwohner_vs_c02\"] = df\n",
    "\n",
    "\n",
    "    def get_table(self, name: str) -> pd.DataFrame:\n",
    "        return self.tables.get(name)\n",
    "\n",
    "    def get_all_tables(self) -> dict:\n",
    "        return self.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b217367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f08bed0",
   "metadata": {},
   "source": [
    "## 3 - BigQuery Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "088f775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from pandas_gbq import to_gbq\n",
    "import os\n",
    "\n",
    "class BigQueryUploader:\n",
    "    def __init__(self, project_id: str, credentials_path: str):\n",
    "        self.project_id = project_id\n",
    "        self.credentials_path = credentials_path\n",
    "        self.credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "\n",
    "    def upload_tables(self, tables: dict, if_exists: str = \"replace\"):\n",
    "        \"\"\"\n",
    "        tables: dict im Format {\n",
    "            \"name1\": {\n",
    "                \"dataframe\": df1,\n",
    "                \"dataset\": \"mein_dataset\",\n",
    "                \"table\": \"meine_tabelle\"\n",
    "            },\n",
    "            ...\n",
    "        }\n",
    "        \"\"\"\n",
    "        for name, config in tables.items():\n",
    "            df = config[\"dataframe\"]\n",
    "            dataset = config[\"dataset\"]\n",
    "            table = config[\"table\"]\n",
    "            full_table_name = f\"{dataset}.{table}\"\n",
    "\n",
    "            print(f\"⬆️ Lade {name} hoch nach: {full_table_name}...\")\n",
    "\n",
    "            try:\n",
    "                to_gbq(\n",
    "                    dataframe=df,\n",
    "                    destination_table=full_table_name,\n",
    "                    project_id=self.project_id,\n",
    "                    credentials=self.credentials,\n",
    "                    if_exists=if_exists\n",
    "                )\n",
    "                print(f\"✅ {name} erfolgreich hochgeladen.\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Fehler beim Hochladen von {name}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00082593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬆️ Lade kpi_pro_jahr hoch nach: energie_daten.kpi_pro_jahr...\n",
      "✅ kpi_pro_jahr erfolgreich hochgeladen.\n",
      "\n",
      "⬆️ Lade lookerstudio_base hoch nach: energie_daten.lookerstudio_base...\n",
      "✅ lookerstudio_base erfolgreich hochgeladen.\n",
      "\n",
      "⬆️ Lade energiemix_pro_jahr hoch nach: energie_daten.energiemix_pro_jahr...\n",
      "✅ energiemix_pro_jahr erfolgreich hochgeladen.\n",
      "\n",
      "⬆️ Lade gemeindeentwicklung hoch nach: energie_daten.gemeindeentwicklung...\n",
      "✅ gemeindeentwicklung erfolgreich hochgeladen.\n",
      "\n",
      "⬆️ Lade gemeindedetails hoch nach: energie_daten.gemeindedetails...\n",
      "✅ gemeindedetails erfolgreich hochgeladen.\n",
      "\n",
      "⬆️ Lade einwohner_vs_c02 hoch nach: energie_daten.einwohner_vs_c02...\n",
      "✅ einwohner_vs_c02 erfolgreich hochgeladen.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyse und Uploadinfos vorbereiten\n",
    "analyse = AnalyseC02Data(df_c02)\n",
    "upload_dict = {}\n",
    "for name, df in analyse.get_all_tables().items():\n",
    "    upload_dict[name] = {\n",
    "        \"dataframe\": df,\n",
    "        \"dataset\": \"energie_daten\",\n",
    "        \"table\": name  # Tabelle im BQ trägt denselben Namen wie die Analyse\n",
    "    }\n",
    "\n",
    "#Upload\n",
    "uploader = BigQueryUploader(\n",
    "    project_id=\"c02-tg\",\n",
    "    credentials_path=os.path.join(os.pardir, \"secrets\", \"bigquery-service-account-c02-tg.json\")\n",
    ")\n",
    "uploader.upload_tables(upload_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe34b5",
   "metadata": {},
   "source": [
    "# Aufgabe 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b600f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2ee6b2d",
   "metadata": {},
   "source": [
    "Ist dein Docker-Image eine Web-App oder ein Batch-Job?\n",
    "\n",
    "Wenn es ein Batch-Job ist (z.B. Python-Script, das einmal läuft und endet), dann ist Cloud Run nicht ideal, weil es für dauerhafte Dienste gedacht ist, die HTTP-Requests annehmen. Für geplante Batch-Jobs kannst du besser Cloud Scheduler + Cloud Run Jobs oder Cloud Functions verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bebcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Docker\n",
    "\n",
    "#Build image:\n",
    "docker build -t europe-west1-docker.pkg.dev/c02-tg/docker-images/c02-automation:latest .\n",
    "\n",
    "#Push image to Artifact Registry Repo\n",
    "docker push europe-west1-docker.pkg.dev/c02-tg/docker-images/c02-automation:latest\n",
    "\n",
    "#Update Cloud Run Job to latest image\n",
    "gcloud run jobs update c02-automation-job --image=europe-west1-docker.pkg.dev/c02-tg/docker-images/c02-automation:latest --region=europe-west1\n",
    "\n",
    "#Test Job (manuell)\n",
    "gcloud run jobs execute c02-automation-job --region=europe-west1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cloud Run Job\n",
    "path für cmd = C:\\Users\\Buddy\\AppData\\Local\\Google\\Cloud SDK\n",
    "\n",
    "#Check next automated update\n",
    "gcloud scheduler jobs describe c02-automation-job-schedule --location=europe-west1\n",
    "\n",
    "#Change Time to automatically update\n",
    "gcloud scheduler jobs update pubsub c02-automation-job-schedule --schedule=\"0 11 * * *\" --location=europe-west1 --time-zone=\"Europe/Berlin\" \n",
    "\n",
    "# Liste aller jobs\n",
    "gcloud scheduler jobs list --location=europe-west1\n",
    "\n",
    "# Log des letzten Jobs\n",
    "gcloud logging read \"resource.type=cloud_run_revision AND resource.labels.service_name=c02-automation-job\" --limit=50 --order=desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb482198",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Webinterface\n",
    "\n",
    "# Cloud Scheduler Übersicht (Job-Zeitplan ansehen & ändern)\n",
    "https://console.cloud.google.com/cloudscheduler?project=c02-tg&inv=1&invt=Ab4YwQ\n",
    "\n",
    "# Cloud Run Jobs\n",
    "https://console.cloud.google.com/run/jobs?project=c02-tg&inv=1&invt=Ab4YwQ\n",
    "\n",
    "# Artifact Registry (Docker-Images)\n",
    "https://console.cloud.google.com/artifacts/docker/c02-tg/europe-west1/docker-images?project=c02-tg&invt=Ab4YwQ&inv=1\n",
    "\n",
    "# Logs der letzten Jobs\n",
    "https://console.cloud.google.com/logs/query;cursorTimestamp=2025-08-02T08:30:06.787513805Z;duration=PT1H?project=c02-tg&inv=1&invt=Ab4YwQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68128c9",
   "metadata": {},
   "source": [
    "Zusammenfassung der IT-Infrastruktur & Begründung\n",
    "\n",
    "- Codeentwicklung & Image\tLokale Entwicklungsumgebung + Docker\tEinfaches Verpacken und Versionieren der Python-Anwendung, um eine portable Laufumgebung sicherzustellen.\n",
    "- Container Registry\tGoogle Artifact Registry\tSichere und zentral verwaltete Speicherung von Container-Images in der Google Cloud, optimiert für Cloud Run.\n",
    "- Serverless Ausführung\tGoogle Cloud Run (managed)\tAutomatische Skalierung, keine Serververwaltung, ideal für einmal täglich ausgeführte Jobs, da Kosten nur bei Nutzung anfallen.\n",
    "- Job Scheduling\tGoogle Cloud Scheduler\tVerlässliche und flexible Steuerung der Ausführungszeit (Cronjobs) in der Cloud, native Integration mit Pub/Sub und Cloud Run.\n",
    "- Kommunikation Job-Auslöser → Job\tGoogle Pub/Sub (Topic)\tEntkoppelte, asynchrone Nachrichtenvermittlung, damit der Scheduler Cloud Run Jobs triggert, ohne direkt Services zu koppeln.\n",
    "- Datenbank / Storage\tBigQuery\tSchnelle, skalierbare Analyseplattform, ideal für große Datenmengen, die das Python-Script täglich aktualisiert.\n",
    "\n",
    "Warum Cloud Run Job?\n",
    "Cloud Run ist optimal für batch-artige Jobs, da keine dauerhaften Ressourcen benötigt werden, automatische Skalierung und einfache Integration in die Google Cloud Plattform vorhanden sind. Zudem laufen Jobs in Containern, was die Portabilität sicherstellt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d46f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 5)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m<tokenize>:5\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mPub/Sub Topic (Nachricht wird gesendet)\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "Cloud Scheduler (mit Uhrzeit & Topic) \n",
    "         ↓\n",
    "   Pub/Sub Topic (Nachricht wird gesendet)\n",
    "         ↓\n",
    "Cloud Function (hört zu & startet Cloud Run Job)\n",
    "         ↓\n",
    "Cloud Run Job (dein Docker-Image mit main.py läuft los)\n",
    "\n",
    "URL Listener:\n",
    "https://trigger-job-function-stb4zjlreq-ew.a.run.app\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75f066d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_C02_TG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
